import torch
import re
import numpy as np

from torch.utils.data import Dataset
from sklearn.feature_extraction import FeatureHasher

from utils import *




class load_datasets(Dataset):
    def __init__(self, args):
        super(Dataset, self).__init__()

        malware_files = get_files_name(args.malware_dir)
        benignware_files = get_files_name(args.benignware_dir)

        hasher = FeatureHasher(30000)
        self.datasets = np.asarray(
            [get_string_features(path, hasher) for path in malware_files + benignware_files]
        )
        self.labels = np.asarray(
            [1 for _ in range(len(malware_files))] + [0 for _ in range(len(benignware_files))]
        )
        
    def __len__(self):
        return len(self.datasets)

    def __getitem__(self, idx):
        return torch.tensor(self.datasets[idx]), torch.tensor(self.labels[idx])



def get_string_features(path, hasher):
    regex = r'[ -~]{5,}'
    pattern = re.compile(regex)

    # get string
    with open(path, errors='ignore', encoding='ascii') as f:
        b2a_data = f.read()
    strings = pattern.findall(b2a_data)

    # hashing
    string_features = {}
    for string in strings:
        string_features[string] = 1
    
    hashed_features = hasher.transform([string_features])
    hashed_features = hashed_features.todense()
    hashed_features = np.array(hashed_features)
    hashed_features = hashed_features[0]
    
    return hashed_features    
