from configparser import Interpolation
from sys import implementation
import matplotlib
import torch
import torch.nn
import torch.nn.functional as F
from torch.utils.data import DataLoader

from load_datasets import *
from sklearn.model_selection import train_test_split
from ml_model import ML_model
from model import *
import time
import pickle as pkl

import xgboost as xgb
import numpy as np
import matplotlib.pyplot as plt
import evaluation
import random
import itertools

def train(args):
    '''
    ## Deep Learning using FNN\n
    batch size : 64
    shuffled : true
    '''
    datasets = load_datasets(args)
    data_loader = DataLoader(
        datasets,
        batch_size=64,
        shuffle=True
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = Classifier(datasets.size(), device)
    model.train()

    epochs = 2
    start_time = time.time()
    for epoch in range(epochs):
        model.losses = []
        for data, label in data_loader:
            data = data.to(device, dtype=torch.float32)
            label = label.to(device, dtype=torch.float32)
            model._train(data, label)
        print(f"[{epoch} epoch] mean loss : {sum(model.losses) / len(data_loader):.3f}")
    print(f"model fitted\t({time.time() - start_time:.3f}sec)")
    torch.save(model.state_dict(), 'model.pt')
    return

def test(args):
    def visualized_score(prediction, pred_probas, target, evaluation_type):
        fig, ax = plt.subplots(1, 1, figsize=(25, 10))
        if evaluation_type == 'ROC_curve':
            evaluation.ROC_curve(pred_probas, target, 'deep learning', ax, 'dl')
        elif evaluation_type == 'confusion_matrix':
            evaluation.confusion_matrix(prediction, target, 'deep learning', ax, 'dl')
        plt.savefig(f"./visualized_score/deep_learning_{evaluation_type}.png")
        plt.clf()

    datasets = load_datasets(args)
    data_loader = DataLoader(
        datasets,
        batch_size=1,
        shuffle=False
    )
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = Classifier(datasets.size(), device)
    model.eval()
    model.load_state_dict(torch.load('model.pt'))

    cnt = 0
    target, prediction, pred_probas = [], [], []
    with torch.no_grad():
        for data, label in data_loader:
            outputs = model._test(data, label)
            output = torch.argmax(outputs, dim=1).item()
            label = label.item()
            
            target.append(label)
            prediction.append(output)
            pred_probas.append(F.softmax(outputs))

            # print(f"predicted : {outputs}\tactual : {label}")
            if output == label:
                cnt += 1

    print(f"accuaracy : {(cnt / len(data_loader)) * 100.:.3f}%")

    # visualization
    visualized_score(prediction, pred_probas, target, 'ROC_curve')
    visualized_score(prediction, pred_probas, target, 'confusion_matrix')
    


def ml_train(args):
    def train(train_X, test_X, train_y, test_y, instances, names):
        for idx, (instance, name) in enumerate(zip(instances, names)):
            start_time = time.time()
            instance.fit(train_X, train_y)         # training
            print(f"{name} fitted\t({time.time() - start_time:.3f}sec)")
            pkl.dump(instance, open(f"{name}.pkl", "wb+"))
            print(f"{name}'s score : {instance.score(test_X, test_y)*100:.3f}%")
        return instances


    args.mode = 'train'
    datasets = load_datasets(args)
    
    train_X, test_X = [], []
    train_y, test_y = [], []
    for (train_data, train_label), (test_data, test_label) in zip(datasets.train_set, datasets.test_set):
        train_X.append(train_data); test_X.append(test_data)
        train_y.append(train_label); test_y.append(test_label)
    train_X = np.array(train_X); test_X = np.array(test_X)
    train_y = np.array(train_y); test_y = np.array(test_y)
    
    models = ML_model()
    names = ['LogisticRegression', 'RandomForestClassifier', 'XGBClassifier']
    instances = []
    for name in names:
        instances.append(models(args, name))

    # visualized
    instances = train(train_X, test_X, train_y, test_y, instances, names)

    return

def ml_test(args):
    def test(train_X, test_X, train_y, test_y, instances, names):
        for idx, (instance, name) in enumerate(zip(instances, names)):      
            # instance.fit(test_X, test_y)      
            # print(f"{name}'s score : {instance.score(test_X, test_y)*100:.3f}%")
            pass
        return instances

    def visualized_score(train_X, test_X, train_y, test_y, instances, names, evaluate_type):
        fig, ax = plt.subplots(
            1, len(names), 
            figsize=(25, 10),
            gridspec_kw={'width_ratios': [1, 1, 1]}
        )
        for idx, (instance, name) in enumerate(zip(instances, names)):
            if evaluate_type == 'ROC_curve':
                pred_probas = instance.predict_proba(test_X)[:,-1]
                ax[idx] = evaluation.ROC_curve(pred_probas, test_y, name, ax[idx], mode='ml')
            elif evaluate_type == 'confusion_matrix':
                pred_y = instance.predict(test_X)
                ax[idx] = evaluation.confusion_matrix(pred_y, test_y, name, ax[idx], mode='ml')
            
        plt.savefig(f'./visualized_score/ml_{evaluate_type}.png')
        plt.clf()

    datasets = load_datasets(args)
    train_X, test_X = [], []
    train_y, test_y = [], []
    for (train_data, train_label), (test_data, test_label) in zip(datasets.train_set, datasets.test_set):
        train_X.append(train_data); test_X.append(test_data)
        train_y.append(train_label); test_y.append(test_label)
    train_X = np.array(train_X); test_X = np.array(test_X)
    train_y = np.array(train_y); test_y = np.array(test_y)

    models = ML_model()
    names = ['LogisticRegression', 'RandomForestClassifier', 'XGBClassifier']
    instances = []
    for name in names:
        instances.append(models(args, name))

    # test(train_X, test_X, train_y, test_y, instances, names)
    visualized_score(train_X, test_X, train_y, test_y, instances, names, 'ROC_curve')
    visualized_score(train_X, test_X, train_y, test_y, instances, names, 'confusion_matrix')
    return
    
def EDA(args):
    '''
    ## EDA\n
    - using test dataset
    - 128 * 128
    '''
    datasets = load_datasets(args)
    test_X, test_y = [], []
    for (test_data, test_label) in datasets.test_set:
        test_X.append(test_data)
        test_y.append(test_label)
    test_X = np.array(test_X)
    test_y = np.array(test_y)
    
    # to img
    img_cnt = 5
    benignwares = test_X[np.where(test_y == 0)[0]]
    np.random.shuffle(benignwares)
    benignwares = benignwares[:img_cnt]
    dim = int(np.sqrt(benignwares[0].shape[0]))
    benignwares = np.clip(benignwares.reshape(-1, dim, dim), -1, 1)
        
    malwares = test_X[np.where(test_y == 1)[0]]
    np.random.shuffle(malwares)
    malwares = malwares[:img_cnt]
    malwares = np.clip(malwares.reshape(-1, dim, dim), -1, 1)

    fig, ax = plt.subplots(2, img_cnt)
    for i, j in itertools.product(range(2), range(img_cnt)):
        if i == 0:
            ax[i][j].imshow(
                benignwares[j],
                interpolation='none',
                cmap='gray',
                vmin=-1,
                vmax=1
            )
            ax[i][j].set_title('benignware', fontsize=8)
        else:
            ax[i][j].imshow(
                malwares[j],
                interpolation='none',
                cmap='gray',
                vmin=-1,
                vmax=1                
            )
            ax[i][j].set_title('malware', fontsize=8)
        ax[i][j].set_xticks([])
        ax[i][j].set_yticks([])

    plt.savefig('img.png')
    plt.clf()
    return