from numpy import dtype
import torch
import torch.nn
import torch.nn.functional as F
from torch.utils.data import DataLoader

from load_datasets import *
from sklearn.model_selection import train_test_split
from model import *
import time
import evaluation as eval

def train(args):
    datasets = load_datasets(args)

    data_loader = DataLoader(
        datasets,
        batch_size=64,
        shuffle=True
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = Classifier(datasets.size(), device)
    model.train()

    epochs = 2
    for epoch in range(epochs):
        start_time = time.time()
        model.losses = []
        for data, label in data_loader:
            data = data.to(device, dtype=torch.float32)
            label = label.to(device, dtype=torch.float32)

            model._train(data, label)
        print(f"[{epoch} epoch] mean loss : {sum(model.losses) / len(data_loader):.3f}\t({time.time() - start_time:.3f}sec)")

    torch.save(model.state_dict(), 'model.pt')


def test(args):
    datasets = load_datasets(args)

    data_loader = DataLoader(
        datasets,
        batch_size=1,
        shuffle=False
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = Classifier(datasets.size(), device)
    model.eval()

    model.load_state_dict(torch.load('model.pt'))

    cnt = 0
    target = []
    prediction = []
    
    with torch.no_grad():
        for data, label in data_loader:
            outputs = model._test(data, label)
            outputs = (outputs.squeeze() > 0.5).float()
            label = label.squeeze().item()

            target.append(label)
            prediction.append(outputs.item())

            # print(f"predicted : {outputs}\tactual : {label}")
            if outputs.long().item() == label:
                cnt += 1

    print(f"accuaracy : {(cnt / len(data_loader)) * 100.:.3f}%")
    eval.evaluation_score.f1_score(prediction, target)    
    eval.evaluation_score.confusion_matrix(prediction, target)
    eval.evaluation_score.Roc_curve(prediction, target)


    return